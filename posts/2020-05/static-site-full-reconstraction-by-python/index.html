<!DOCTYPE html>
<html lang="zh_cn">
<head>
<meta charset="utf-8">
<meta name="description" content="将一个静态站点完整地扒拉下来。">
<meta name="viewport" content="width=device-width">
<title>使用 Python 对静态站点进行整站重建 | ZomHub</title>
<link href="../../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" hreflang="zh_cn" href="../../../rss.xml">
<link rel="canonical" href="https://blog.zombie110year.top/posts/2020-05/static-site-full-reconstraction-by-python/">
<link rel="icon" href="../../../favicon.ico" sizes="256x256">
<link rel="icon" href="../../../favicon.png" sizes="512x512">
<meta name="author" content="Zombie110year">
<meta name="robots" content="noindex">
<meta property="og:site_name" content="ZomHub">
<meta property="og:title" content="使用 Python 对静态站点进行整站重建">
<meta property="og:url" content="https://blog.zombie110year.top/posts/2020-05/static-site-full-reconstraction-by-python/">
<meta property="og:description" content="将一个静态站点完整地扒拉下来。">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2020-05-18T15:54:14+08:00">
<meta property="article:tag" content="python">
<meta property="article:tag" content="spider">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
</head>
<body>
    <a href="#content" class="sr-only sr-only-focusable">跳到主内容</a>
    <div id="container">
            <header id="header"><h1 id="brand"><a href="https://blog.zombie110year.top/" title="ZomHub" rel="home">

        <span id="blog-title">ZomHub</span>
    </a></h1>

        
            <nav id="menu"><ul>
<li><a href="../../../archive.html">归档</a></li>
                <li><a href="../../../categories/">标签</a></li>
                <li><a href="../../../rss.xml">订阅</a></li>

    
    
    
    </ul></nav></header><main id="content"><article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="." class="u-url">使用 Python 对静态站点进行整站重建</a></h1>

        <div class="metadata">
            <p class="byline author vcard p-author h-card"><span class="byline-name fn p-name" itemprop="author">
                    Zombie110year
            </span></p>
            <p class="dateline">
            <a href="." rel="bookmark">
            <time class="published dt-published" datetime="2020-05-18T15:54:14+08:00" itemprop="datePublished" title="2020-05-18 15:54">2020-05-18 15:54</time></a>
            </p>
                    <p class="sourceline"><a href="index.rst" class="sourcelink">源文件</a></p>

        </div>
        
    </header><div class="e-content entry-content" itemprop="articleBody text">
    <div>
<p>玩玩爬虫。</p>
<div class="contents topic" id="id1">
<p class="topic-title">目录</p>
<ul class="simple">
<li><p><a class="reference internal" href="#id2" id="id6">一个全站爬虫的要素</a></p></li>
<li>
<p><a class="reference internal" href="#id3" id="id7">开发环境的准备</a></p>
<ul>
<li><p><a class="reference internal" href="#lxml" id="id8">lxml 库的基本用法</a></p></li>
<li><p><a class="reference internal" href="#partially-initialized-module" id="id9">partially initialized module</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#id5" id="id10">程序设计</a></p></li>
</ul>
</div>
<!-- TEASER_END -->
<div class="section" id="id2">
<h2><a class="toc-backref" href="#id6">一个全站爬虫的要素</a></h2>
<p>一个静态站点的所有资源都处于 HTML + CSS + JavaScript + Media Resource 的范畴之内，在爬取时忽略所有动态因素，如 AJAX、HTML 表单等。</p>
<p>在爬取的过程中，可能会遇到以下困难：</p>
<dl class="simple">
<dt>重复爬取</dt>
<dd>
<p>当多个页面拥有相同的资源引用时，为了避免重复爬取，可以通过记录每一份成功下载资源的绝对链接，在开始下载前检测此资源是否已经被爬取来达成。
这个功能可以通过 Python 标准库的 <code class="docutils literal">urllib.parse</code> 模块来实现。</p>
</dd>
<dt>循环跳转</dt>
<dd>
<p>若存在一个「页面环」：A-&gt;B-&gt;C-&gt;A... 等等，将形成循环跳转的情况，如果爬虫一头栽进去，就可能进入死循环。
如果网站没有通过符号链接来刻意制作陷阱的话，这个问题也可以通过绝对链接来解决；否则，需要为爬虫加上一个最大路径深度的设置。</p>
</dd>
</dl>
<p>为了搞整站重建，我们需要爬取这些目标：</p>
<dl>
<dt>从起点出发，所有可以通过超链接访问到的资源</dt>
<dd>
<p>在这个步骤中，需要在爬取并下载文件的同时，在本地文件系统建立与远程同步的文件结构。打个比方，如果有个 URL 为 <code class="docutils literal"><span class="pre">https://example.com/a/b/c/hello.html</span></code> 的文件，那么在本地文件系统，从工作目录开始，将它保存为 <code class="docutils literal">./example.com/a/b/c/hello.html</code>。</p>
</dd>
<dt>爬取所有存储在外站的资源</dt>
<dd>
<p>有些静态站点将媒体文件、CSS 或 JS 资源存储在 CDN 中，为了完成重建，需要把它们也爬取过来。并同样构造等价的文件结构。
为了让这些资源能够被一个 HTTP 服务包全，打算建立在该站点对应的存储目录下的 <code class="docutils literal"><span class="pre">.ssc-external</span></code> 文件夹里（ssc 是 static site copy 的缩写）。</p>
</dd>
<dt>解析已爬取的 HTML 文件，将外站资源重定向至本地</dt>
<dd>
<p>解析出 HTML 中的外站链接，将它们一律解析成:</p>
<pre class="literal-block">/.ssc-external/{scheme}-{domain}/{path}</pre>
</dd>
</dl>
</div>
<div class="section" id="id3">
<h2><a class="toc-backref" href="#id7">开发环境的准备</a></h2>
<p>打算直接上 aiohttp 模块、使用 lxml 解析 HTML。</p>
<div class="section" id="lxml">
<h3><a class="toc-backref" href="#id8">lxml 库的基本用法</a></h3>
<pre class="code python"><a name="rest_code_a2186ed6e45a4197a1b8353a8004a01a-1"></a><span class="kn">from</span> <span class="nn">lxml.etree</span> <span class="kn">import</span> <span class="n">HTML</span><span class="p">,</span> <span class="n">HTMLParser</span>
<a name="rest_code_a2186ed6e45a4197a1b8353a8004a01a-2"></a>
<a name="rest_code_a2186ed6e45a4197a1b8353a8004a01a-3"></a><span class="n">et</span> <span class="o">=</span> <span class="n">HTML</span><span class="p">(</span><span class="s2">"&lt;span&gt;Hello&lt;/span"</span><span class="p">,</span> <span class="n">base_url</span><span class="o">=</span><span class="n">url</span><span class="p">)</span>
</pre>
<ul class="simple">
<li><p>一般通过 xpath 来选择元素</p></li>
<li><p>base_url 用来解析内部的相对链接。</p></li>
</ul>
</div>
<div class="section" id="partially-initialized-module">
<h3><a class="toc-backref" href="#id9">partially initialized module</a></h3>
<p>在运行时，由于划分了几个文件，而且为了提供类型标注而产生了循环导入，
为此，使用参考自 StackOverflow 的方法 <a class="footnote-reference brackets" href="#so-1" id="id4">1</a>：</p>
<ol class="arabic simple">
<li><p>在 <code class="docutils literal">if typing.TYPE_CHECKING</code> 块下导入起类型标注作用的模块</p></li>
<li><p><code class="docutils literal">from __future__ import annotations</code> 以添加向前类型引用的支持（Python 3.7 以上可用，Python 3.9 正式支持）</p></li>
</ol>
<dl class="footnote brackets">
<dt class="label" id="so-1"><span class="brackets"><a class="fn-backref" href="#id4">1</a></span></dt>
<dd>
<p><a class="reference external" href="https://stackoverflow.com/questions/39740632/python-type-hinting-without-cyclic-imports">https://stackoverflow.com/questions/39740632/python-type-hinting-without-cyclic-imports</a></p>
</dd>
</dl>
</div>
</div>
<div class="section" id="id5">
<h2><a class="toc-backref" href="#id10">程序设计</a></h2>
<p>当我们完成 <a class="reference internal" href="#id2">一个全站爬虫的要素</a> 章节中所确定的任务时，需要这些角色：</p>
<dl class="simple">
<dt>发送网络请求（RequestSender）</dt>
<dd>
<p>从 URL 池中读取一个链接，发送请求，获取响应。</p>
</dd>
<dt>响应解析任务分配（ResponseManager）</dt>
<dd>
<p>从 RequestSender 获取一个响应，根据 MIMEType 决定下一步的策略。</p>
</dd>
<dt>解析 HTML （HTMLSolver）</dt>
<dd>
<p>从 ResponseManager 获取一个 HTML 响应，解析出该网页引用的资源链接；
然后放入 URL 池调度系统。而此 HTML 响应的完整内容，也放入文件调度系统进行保存作业。</p>
</dd>
<dt>保存静态资源（StaticFileSolver）</dt>
<dd>
<p>从 ResponseManager 获取一个 非 HTML 响应。直接转交给文件调度系统。</p>
</dd>
<dt>文件调度系统（DiskManager）</dt>
<dd>
<p>从各 Solver 获取响应，然后将其按照一定规则保存到本地文件系统。</p>
</dd>
<dt>URL 调度系统（URLManager）</dt>
<dd>
<p>管理 URL 池。分 to_visit 和 visited 两个池，前者用一个队列，后者用一个集合。
如果一个 URL 已经存在于 visited，那么就不会将其放入 to_visit。</p>
</dd>
</dl>
<p>以上各角色的关系如下图：</p>
<div class="figure">
<img alt="/images/static-site-full-reconstraction-by-python-uml.drawio.svg" src="../../../images/static-site-full-reconstraction-by-python-uml.drawio.svg" style="height: 400px;"><p class="caption">UML 图</p>
</div>
</div>
</div>
    </div>
    <aside class="postpromonav"><nav><ul itemprop="keywords" class="tags">
<li><a class="tag p-category" href="../../../categories/python/" rel="tag">python</a></li>
            <li><a class="tag p-category" href="../../../categories/spider/" rel="tag">spider</a></li>
        </ul></nav></aside><script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script><script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous" onload="autoRenderKatex();"></script><script>
        function autoRenderKatex() {
            renderMathInElement(document.body,
                {
                    
delimiters: [
    {left: "$$", right: "$$", display: true},
    {left: "\\[", right: "\\]", display: true},
    {left: "\\begin{equation*}", right: "\\end{equation*}", display: true},
    {left: "\\begin{align*}", right: "\\end{align*}", display: true},
    {left: "$", right: "$", display: false},
    {left: "\\(", right: "\\)", display: false}
]

                }
            );
        }
        </script></article></main><footer id="footer"><p>Contents © 2020 <a href="mailto:zombie110year@outlook.com">Zombie110year</a> - Powered by <a href="https://getnikola.com" rel="nofollow">Nikola</a> CC BY-NC-SA 4.0</p>
            
        </footer>
</div>

                <script src="../../../assets/js/all-nocdn.js"></script><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
    </script>
</body>
</html>
